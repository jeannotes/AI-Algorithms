{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import SVMMod2 as Mod\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X,y = data.data,data.target\n",
    "y[y!=1]=-1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameters and initial values\n",
    "C = 100.0\n",
    "m = len(X_train)\n",
    "initial_alphas = np.zeros(m)\n",
    "initial_b = 0.0\n",
    "\n",
    "# Set tolerances\n",
    "tol = 0.001 # error tolerance\n",
    "eps = 0.001 # alpha tolerance\n",
    "\n",
    "# Instantiate model\n",
    "model = Mod.SMOModel(X_train, y_train, C, Mod.gaussian_kernel,\n",
    "                 initial_alphas, initial_b, np.zeros(m), tol, eps)\n",
    "\n",
    "# Initialize error cache\n",
    "initial_error = Mod.decision_function(model.alphas, model.y, model.kernel,\n",
    "                                  model.X, model.X, model.b) - model.y\n",
    "model.errors = initial_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.333333333333329"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = Mod.train(model) \n",
    "y_pred = Mod.decision_function(output.alphas,output.y,Mod.gaussian_kernel,output.X,X_test,output.b)\n",
    "y_pred[y_pred>0]=1\n",
    "y_pred[y_pred<0]=-1\n",
    "100*sum(y_test==y_pred)/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC(C=100.0,kernel='rbf',gamma=1)\n",
    "svc.fit(X_train,y_train)\n",
    "svc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrinking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "C-Support Vector Classification.\n",
       "\n",
       "The implementation is based on libsvm. The fit time complexity\n",
       "is more than quadratic with the number of samples which makes it hard\n",
       "to scale to dataset with more than a couple of 10000 samples.\n",
       "\n",
       "The multiclass support is handled according to a one-vs-one scheme.\n",
       "\n",
       "For details on the precise mathematical formulation of the provided\n",
       "kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
       "other, see the corresponding section in the narrative documentation:\n",
       ":ref:`svm_kernels`.\n",
       "\n",
       "Read more in the :ref:`User Guide <svm_classification>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "C : float, optional (default=1.0)\n",
       "    Penalty parameter C of the error term.\n",
       "\n",
       "kernel : string, optional (default='rbf')\n",
       "     Specifies the kernel type to be used in the algorithm.\n",
       "     It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
       "     a callable.\n",
       "     If none is given, 'rbf' will be used. If a callable is given it is\n",
       "     used to pre-compute the kernel matrix from data matrices; that matrix\n",
       "     should be an array of shape ``(n_samples, n_samples)``.\n",
       "\n",
       "degree : int, optional (default=3)\n",
       "    Degree of the polynomial kernel function ('poly').\n",
       "    Ignored by all other kernels.\n",
       "\n",
       "gamma : float, optional (default='auto')\n",
       "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
       "    If gamma is 'auto' then 1/n_features will be used instead.\n",
       "\n",
       "coef0 : float, optional (default=0.0)\n",
       "    Independent term in kernel function.\n",
       "    It is only significant in 'poly' and 'sigmoid'.\n",
       "\n",
       "probability : boolean, optional (default=False)\n",
       "    Whether to enable probability estimates. This must be enabled prior\n",
       "    to calling `fit`, and will slow down that method.\n",
       "\n",
       "shrinking : boolean, optional (default=True)\n",
       "    Whether to use the shrinking heuristic.\n",
       "\n",
       "tol : float, optional (default=1e-3)\n",
       "    Tolerance for stopping criterion.\n",
       "\n",
       "cache_size : float, optional\n",
       "    Specify the size of the kernel cache (in MB).\n",
       "\n",
       "class_weight : {dict, 'balanced'}, optional\n",
       "    Set the parameter C of class i to class_weight[i]*C for\n",
       "    SVC. If not given, all classes are supposed to have\n",
       "    weight one.\n",
       "    The \"balanced\" mode uses the values of y to automatically adjust\n",
       "    weights inversely proportional to class frequencies in the input data\n",
       "    as ``n_samples / (n_classes * np.bincount(y))``\n",
       "\n",
       "verbose : bool, default: False\n",
       "    Enable verbose output. Note that this setting takes advantage of a\n",
       "    per-process runtime setting in libsvm that, if enabled, may not work\n",
       "    properly in a multithreaded context.\n",
       "\n",
       "max_iter : int, optional (default=-1)\n",
       "    Hard limit on iterations within solver, or -1 for no limit.\n",
       "\n",
       "decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
       "    Whether to return a one-vs-rest ('ovr') decision function of shape\n",
       "    (n_samples, n_classes) as all other classifiers, or the original\n",
       "    one-vs-one ('ovo') decision function of libsvm which has shape\n",
       "    (n_samples, n_classes * (n_classes - 1) / 2).\n",
       "\n",
       "    .. versionchanged:: 0.19\n",
       "        decision_function_shape is 'ovr' by default.\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       *decision_function_shape='ovr'* is recommended.\n",
       "\n",
       "    .. versionchanged:: 0.17\n",
       "       Deprecated *decision_function_shape='ovo' and None*.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional (default=None)\n",
       "    The seed of the pseudo random number generator to use when shuffling\n",
       "    the data.  If int, random_state is the seed used by the random number\n",
       "    generator; If RandomState instance, random_state is the random number\n",
       "    generator; If None, the random number generator is the RandomState\n",
       "    instance used by `np.random`.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "support_ : array-like, shape = [n_SV]\n",
       "    Indices of support vectors.\n",
       "\n",
       "support_vectors_ : array-like, shape = [n_SV, n_features]\n",
       "    Support vectors.\n",
       "\n",
       "n_support_ : array-like, dtype=int32, shape = [n_class]\n",
       "    Number of support vectors for each class.\n",
       "\n",
       "dual_coef_ : array, shape = [n_class-1, n_SV]\n",
       "    Coefficients of the support vector in the decision function.\n",
       "    For multiclass, coefficient for all 1-vs-1 classifiers.\n",
       "    The layout of the coefficients in the multiclass case is somewhat\n",
       "    non-trivial. See the section about multi-class classification in the\n",
       "    SVM section of the User Guide for details.\n",
       "\n",
       "coef_ : array, shape = [n_class-1, n_features]\n",
       "    Weights assigned to the features (coefficients in the primal\n",
       "    problem). This is only available in the case of a linear kernel.\n",
       "\n",
       "    `coef_` is a readonly property derived from `dual_coef_` and\n",
       "    `support_vectors_`.\n",
       "\n",
       "intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
       "    Constants in decision function.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
       ">>> y = np.array([1, 1, 2, 2])\n",
       ">>> from sklearn.svm import SVC\n",
       ">>> clf = SVC()\n",
       ">>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)\n",
       ">>> print(clf.predict([[-0.8, -1]]))\n",
       "[1]\n",
       "\n",
       "See also\n",
       "--------\n",
       "SVR\n",
       "    Support Vector Machine for Regression implemented using libsvm.\n",
       "\n",
       "LinearSVC\n",
       "    Scalable Linear Support Vector Machine for classification\n",
       "    implemented using liblinear. Check the See also section of\n",
       "    LinearSVC for more comparison element.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
